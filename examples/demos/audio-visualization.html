<html>
	<head>
		<title>NEJS 2016 - Audio Visualization</title>

		<style>
		@keyframes grow-fade {
			0% {
				transform: rotate(0deg) scale(1) translate3d(0, 0, 0);
				opacity: 1;
			}

			100% {
				transform: rotate(-45deg) scale(2) translate3d(0, 0, 0);
				opacity: 0;
			}
		}

		@keyframes grow-fade-diamond {
			0% {
				transform: rotate(45deg) scale(1) translate3d(0, 0, 0);
				opacity: 1;
			}

			100% {
				transform: rotate(90deg) scale(2) translate3d(0, 0, 0);
				opacity: 0;
			}
		}

		body {
			background: #222;
			width: 100%;
			height: 100%;
			overflow: hidden;
			display: flex;
			align-items: center;
			justify-content: flex-end;
			flex-direction: column;
		}

		.range {
			font-size: 30px;
			position: relative;
			z-index: 9999;
		}

		.btn {
			font-size: 24px;
			margin: 20px 0 40px;
			position: relative;
			z-index: 9999;
		}

		.shape {
			position: absolute;
			opacity: 1;
			transform: scale(1) translate3d(0, 0, 0);
			top: 30%;
			left: 25%;
			animation: grow-fade 1s ease-out;
			animation-fill-mode: forwards;
		}

		.shape.type-1 {
			border-radius: 100%;
			width: 100px;
			height: 100px;
			background: #c0392b;
		}

		.shape.type-2 {
			width: 75px;
			height: 75px;
			background: #2980b9;
		}

		.shape.type-3 {
			width: 50px;
			height: 50px;
			background: #1abc9c;
			transform: rotate(45deg);
			animation: grow-fade-diamond 1s ease-out;
			animation-fill-mode: forwards;
		}

		.shape.type-4 {
			width: 25px;
			height: 25px;
			background: #f39c12;
		}
		</style>
	</head>
	<body>

		<input
			data-filter
			class="range"
			type="range"
			min="0"
			max="20000"
			step="50"
			value="0" />
		<button data-start class="btn">Start</button>

		<script>
		// create web audio context
		const audioCtx = new (window.AudioContext || window.webkitAudioContext)();

		// window dimensions and playing boolean
		const config = {
			width: window.innerWidth,
			height: window.innerHeight,
			playing: false,
		};

		// DOM nodes
		const ui = {
			start: document.querySelector('[data-start]'),
			filter: document.querySelector('[data-filter]'),
		};

		// create analyzer node
		const analyser = audioCtx.createAnalyser();
		// set size of fast fourier transform
		analyser.fftSize = 64;

		// construct Uint8Array for analysis data
		const bufferLength = analyser.frequencyBinCount;
		const dataArray = new Uint8Array(bufferLength);

		// create biquad filter node
		const biquadFilter = audioCtx.createBiquadFilter();

		// set biquad filter values
		biquadFilter.type = "lowpass";
		biquadFilter.frequency.value = ui.filter.value;
		biquadFilter.Q.value = 10;

		// filter to analyser, analyser to output
		biquadFilter.connect(analyser);
		analyser.connect(audioCtx.destination);

		let bufferSource;

		// fetch mp3
		fetch('/assets/digitalsurgeons.mp4')

		// fetch as array buffer
		.then(response => {
			return response.arrayBuffer();
		})
		// decode audio data from array buffer
		.then(arrayBuffer => {
			return audioCtx.decodeAudioData(arrayBuffer);
		})
		.then(decodedAudio => {
			ui.start.addEventListener('click', e => {
				if (config.playing) {
					// stop and disconnect buffer
					bufferSource.stop(0);
					bufferSource.disconnect();

					// update button
					ui.start.innerHTML = 'Start';
					config.playing = false;
				} else {
					// create new buffer and connect to filter
					bufferSource = audioCtx.createBufferSource();
					bufferSource.buffer = decodedAudio;
					bufferSource.loop = true;
					bufferSource.start(0);
					bufferSource.connect(biquadFilter);

					// kick off analysis
					requestAnimationFrame(analyze);

					// update button
					ui.start.innerHTML = 'Stop';
					config.playing = true;
				}

				// set playing to true and reset on ended event
				bufferSource.addEventListener('ended', e => {
					config.playing = false;
				});
			});
		});

		// update biquad filter cutoff frequency with range slider
		ui.filter.addEventListener('input', e => {
			biquadFilter.frequency.value = e.currentTarget.value;
		});

		// call analyze function at 60fps
		function analyze() {
			// get frequency data of audio at this point in time
			analyser.getByteFrequencyData(dataArray);

			// take middle 16 chunks from 32
			const dataSplice = dataArray.slice(8, 16);

			// loop through middle 16 chunks
			dataSplice.forEach((bin, index) => {
				let type = false;

				// set shape type based on frequency and amplitude
				if (index <= 4 && bin > 200) {
					type = 1;
				} else if (index <= 8 && bin > 180) {
					type = 2;
				} else if (index <= 12 && bin > 160) {
					type = 3;
				} else if (index <= 16 && bin > 60) {
					type = 4;
				}

				if (!type) {
					return;
				}

				// add new shape to canvas
				requestAnimationFrame(addShape.bind(this, `type-${type}`));
			});

			// recursivly call function every 60fps
			// stop when audio no longer playing
			if (!config.playing) {
				return;
			}

			requestAnimationFrame(analyze);
		}

		// return random integer between min / max
		function randomNumber(min, max) {
			return Math.floor(Math.random() * (max - min + 1)) + min;
		}

		// add shape to canvas
		function addShape(cls = 'type-4') {
			// create shape div
			const shape = document.createElement('div');

			// calculate random position
			const pos = {
				top: randomNumber(0, config.height),
				left: randomNumber(0, config.width),
			};

			// set shape class and type, default type-4
			shape.classList.add('shape', cls);

			// set position
			shape.style.top = `${pos.top}px`;
			shape.style.left = `${pos.left}px`;

			// add to canvas
			document.body.appendChild(shape);
		}

		console.log(audioCtx);
		console.log(analyser);
		</script>
	</body>
</html>
